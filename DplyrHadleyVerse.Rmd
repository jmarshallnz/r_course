# dplyr and the hadleyverse
### Jonathan Marshall

```{r, setup, echo=FALSE}
library(knitr)
opts_chunk$set(eval=FALSE)
```

## Introduction

Today we'll be covering some of Hadley Wickham's packages.

- dplyr
- tidyr
- lubridate

In addition, we'll be looking at the forward pipe operator which is from the `magrittr` package and makes
sequences of operations a little more intuitive.

## Dataset

The dataset we'll be using today is from the emergency department. It contains 80713 observations over XX variables.

You can read it in using:

*Try the following*
```{r}
ed = read.csv("data/ED.csv", stringsAsFactors = FALSE)
```

Because the dataset is so large, we don't want R to try and print out the results after each command. To prevent this, we'll wrap the data frame in `tbl_df` which overrides the `print` function to avoid printing out too many rows and columns.

*Try the following*
```{r}
library(dplyr)
ed = tbl_df(ed)
ed
```

Now, when `ed` is printed (or subsets thereof) only the first 10 rows are shown, as well as the number of columns that fit the R console.

We can look at what the `ed` dataset contains using `str` in base R, or there is a slightly nicer version in `dplyr` called `glimpse` that formats the output a bit better.

*Try the following*
```{r}
glimpse(ed)
```

One of the things we notice is that there are date variables that have been interpreted as strings. We'll want to start by converting these to dates.

### Dates and times with lubridate

One of the biggest things in working with dates and times is to convert dates to and from strings, and to extract parts of dates (e.g. months, days, years) for summarising data. This is what lubridate is good for.

Firstly, it had the functions `ymd`, `dmy` and `mdy` for converting from string formats into dates. These work out of the box with 'typical' date formats such as 2015-03-20 or 20/03/2015 but can also be used for less fortunate formats, and even for columns of data that aren't consistent in their formatting.

A key point to note is that to convert date strings to dates, you must first have the dates as strings, rather than as factors.

In addition, lubridate can also work with time strings (or date-time strings) using the `hm` and `hms` functions (and `ymd_h`, `ymd_hm`, `ymd_hms` etc.)

*Try the following*
```{r}
library(lubridate)
ymd("2015-01-30")
ymd("2015/1/30")
ymd_hms("2015-01-30 23:11:02")
ymd_hm("2015-01-30 3:11 pm")
ymd("15/1/14")
dmy("15/1/14")
dmy(c("4/5/1998", "15 1 2010"))
dmy(c("4/5/1998", "2015-01-03"))
```

Once you have a date object, you can then use lubridate functions to extract various aspects, compare dates, round dates and so on.

*Try the following*
```{r}
date_time = now()
date_time
day(date_time)
week(date_time)
wday(date_time)
wday(date_time, label=TRUE)
month(date_time, label=TRUE)
year(date_time)
hour(date_time)
quarter(date_time)
round_date(date_time, "hour")
date_time > "2015-10-01"
interval = ymd(20151001) %--% ymd(20151012)
date_time %within% interval
```

We can use this to convert the `ADATE` column.

*Do the following*
```{r}
ed$ADATE = dmy(ed$ADATE)
```

## dplyr

dplyr is a package designed for processing large data frames (the d is for data frame).

The philosophy behind dplyr is to have a relatively small number of 'verbs' that are used to manipulate
data, with each of those verbs taking in a data frame and other parameters, and returning a data frame
as output. dplyr never modifies in-place: The original data frame is untouched and a new copy of it is
returned.

dplyr is designed to work on either local data frames (i.e. data residing in R's memory) or on databases. Any set of dplyr commands have SQL-equivalents, and dplyr generates the SQL so that the data returned to R is minimal (i.e. filtering, sorting, summarising is done by the database).

dplyr makes extensive use of **non-standard evaluation**. Thus, you can reference columns in your dataset by using their name, without quotes. This is particularly good for interactive use, as RStudio includes auto-completion for column names when it is used with piping (see below).

Lastly, dplyr is designed to use lazy evaluation. Thus, it only actually does work on data frames or databases when you need to use the data (e.g. to print it out). If you're working with a database, even if you assign a result to a temporary variable, dplyr won't actually go to the database. It will only go to the database when you need to print, or otherwise process the data using something other than dplyr.

If your data is fairly small, then often doing a database dump at the start might make more sense (e.g. via RMySQL or similar DBI libraries), as subsequent operations will be much faster on an in-memory data frame. If the database is large, or you need 'live' summaries of the database as you go then connecting to the database using `dplyr` and retrieving only the summaries you want might be a better way to go.

For monthly reporting I'd use the first, whereas for hourly reporting, the second method.

### Resources

There are lots of good resources for `dplyr` on the web, including vignettes for the package, as well as presentations and tutorials. Just a few are listed below.

#### Vignettes

```{r}
vignette(package="dplyr")
```

lists the 'introduction', 'data_frame', 'databases' and 'two-table' vignettes. e.g. see

```{r}
library(dplyr)
vignette("introduction")
```

#### Web links

A google search for 'dplyr tutorial' returns a whole heap of useful links, such as

- https://rpubs.com/justmarkham/dplyr-tutorial
- http://genomicsclass.github.io/book/pages/dplyr_tutorial.html
- http://datascience.la/hadley-wickhams-dplyr-tutorial-at-user-2014-part-1/

But there are plenty more. The first and last include video tutorials.

### The verbs

The main verbs for manipulating data on a single table are

- `filter` for filtering rows.
- `arrange` for ordering rows.
- `select`, `rename` for filtering/naming columns.
- `mutate`, `transmute` for creating new columns.
- `summarise` for collapsing a data frame to a single row.

#### filter

Filter is used to find subsets of the rows that satisfy a particular condition defined on the columns by an expression. The syntax is

```{r}
filter(data, expression1, expression2, ...)
```

where `data` is a data frame, `expression1` is an expression on the columns of `data`, as is `expression2` and so on. The expressions have to all be true for an observation to be selected. i.e. if you use two or more expressions it is equivalent to AND'ing them together.

*Try the following*
```{r}
filter(ed, Triage == 4)
filter(ed, Triage %in% c(3,4))
filter(ed, Triage >= 4, Age >= 50)
filter(ed, year(ADATE) == 2012)
```

*Your turn*

1. Filter the dataset to include only those under the age of 5 that presented in 2014 and stayed in hospital for at least 3 days.
2. Find observations of female Pacific Island patients over the age of 65.
3. Find observations of female Pacific or Maori patients over the age of 65.

#### arrange

Arrange is used to order the data by one or more columns, or expressions on the columns. The syntax is

```{r}
arrange(data, column1, column2, ...)
```

where again `data` is a data frame, `column1` etc. are (unquoted) column names. The rows are ordered first (ascending) on column1, then on column2 and so on. You can use `desc(column)` to reverse the order of a particular column (descending order).

If you wish to order on an expression computed from one or more columns, the trick is to use `mutate` to create a new column with the result of the expression, then `arrange` by the new column.

*Try the following*
```{r}
arrange(ed, Triage)
arrange(ed, desc(ADATE))
```

*Your turn*

1. Sort the data by age.
2. Sort the data by decreasing length of hospital stay.

#### select, rename

Select is used to choose a subset of columns. e.g. it is often used to drop columns that are no longer of interest. You can rename a column as you go (by naming the columns you select differently), or alternatively can use `rename` to do this. You can also re-order columns using `select`. The syntax is

```{r}
select(data, col1, col2, ...)
```

to return the `col1` and `col2` columns from the data frame `data`. You can reference columns as if they were ranges as well (e.g. `col1:col2` returns all columns from `col1` to `col2`), and can drop columns by using `-col`. You can rename columns using `foo = col2` to rename `col2` to `foo`.

The syntax for `rename` is the same, with the difference being that `rename` by default keeps all unreferenced columns (in addition to the renamed ones), where as `select` only returns the referenced columns.

*Try the following*
```{r}
select(ed, Triage, ADATE, Age, Gender, ETHGROUP, LoH=Length.of.hospital.stay)
rename(ed, LoH=Length.of.hospital.stay)
```

#### mutate, transmute

Mutate is used to create new columns. The syntax is

```{r}
mutate(data, newcol = expression, newcol2 = expression2, ...)
```

to create two new columns from expressions. You can replace existing columns by naming a result the same as an existing column, and can use `col=NULL` to drop a column.

`transmute` uses the same syntax, but returns only the columns specified rather than all other columns as well.

*Try the following*
```{r}
transmute(ed, dmy_hm(PRESENT), dmy_hm(DEPART))
transmute(ed, LoS = dmy_hm(DEPART) - dmy_hm(PRESENT))
transmute(ed, LoS = as.numeric(dmy_hm(DEPART) - dmy_hm(PRESENT))/60)
transmute(ed, age_group = cut(Age, breaks=c(0,20,40,60,80,110)))
```

*Your turn*
1. Use `mutate` to create a new dataframe `ed2` with `DEPART` and `PRESENT` columns converted to dates.
2. Find the presenting and departing dates for any patients that were in over new years eve in 2012 using `filter` and `select` on `ed2`.

#### summarise

The `summarise` function summarises all the rows in a data frame. It is useful for counting rows, computing summary statistics (median, mean, max, min) and so on. The syntax is

```{r}
summarise(data, name=expression, name2=expression2)
```

where `expression` computes a summary from one (or more) columns in the data. The result is a data frame with a single row containing the `name` and `name2` values.

*Try the following*
```{r}
summarise(ed2, min(PRESENT), max(PRESENT))
```

*Your turn*

1. Find the age of the oldest and youngest patients, and the average age.
2. Find the earliest date of arrival for patients in ED at new years eve 2012.

### Grouped operations

The real power of dplyr comes when the above verbs are applied to groups of data. In particular, the `summarise` function allows you to compute data summaries by group, but all of the other verbs have analogues for grouped data (e.g. `arrange` on grouped data arranges within group, while `filter` filters within group, which is particularly useful for retrieving things like the top 5 results in each group).

The `group_by` verb is the key function. It adds grouping information to the data frame so that subsequent commands are operated on the groups rather than on the entire data set.

*Try the following*
```{r}
eth = group_by(ed, ETHGROUP)
summarise(eth, n())
```

*Your turn*

1. Find the number of observations for each `Age`.
2. Find the median age for each ethnicity.
3. Find the average time in ED for each ethnicity.
4. Find the average time in ED for each ethnicity by age group.

## Pipes

Often we need to chain together a long sequence of verbs to get the things we really want. For example, in order to find the average time in ED for each ethnicity by age group we'd need to:

1. Mutate to convert dates to dates.
2. Mutate to get time in ED from the difference in dates.
3. Mutate to get the age groups.
4. Group by ethnicity and age group.
5. Summarise to get the means.

This could be done using a bunch of temporary data frames

```{r}
edtemp = mutate(ed, DEPART=dmy_hm(DEPART))
edtemp2 = mutate(edtemp, PRESENT=dmy_hm(PRESENT))
edtemp3 = mutate(edtemp2, LoS=as.numeric(DEPART - PRESENT)/60)
edtemp4 = mutate(edtemp3, AgeGroup = cut(Age, c(0, 20, 40, 60, 80, 110)))
edtemp5 = group_by(edtemp4, ETHGROUP, AgeGroup)
summarise(edtemp5, mean(LoS))
```

Or alternatively we could chain the functions together to avoid the temporaries if you don't need them.

```{r}
summarise(
  group_by(
    mutate(
      mutate(
        mutate(
          mutate(ed, DEPART=dmy_hm(DEPART))
          , PRESENT=dmy_hm(PRESENT))
        , LoS=as.numeric(DEPART - PRESENT)/60)
      , AgeGroup = cut(Age, c(0, 20, 40, 60, 80, 110)))
    , ETHGROUP, AgeGroup)
  , mean(LoS))
```

The problem with that is you need to read it inside out. Plus, it's not obvious which parameters are associated with which functions.

Instead, we can use the pipe operator `%>%` to string together functions. What the pipe operator does is it takes
what is on the left hand side and passes it into the first parameter of the right hand side function. The above becomes

```{r}
ed %>%
  mutate(DEPART=dmy_hm(DEPART)) %>%
  mutate(PRESENT=dmy_hm(PRESENT)) %>%
  mutate(LoS=as.numeric(DEPART-PRESENT)/60) %>%
  mutate(AgeGroup=cut(Age, c(0,20,40,60,80,110))) %>%
  group_by(ETHGROUP, AgeGroup) %>%
  summarise(mean(LoS))
```

This is much easier to read. You can see the flow of the data through the chain of functions.

*Your turn*

1. Find the average length of stay by month.
2. Find the average length of stay by day.
3. Find the number of arrivals per hour per day of the week.

## tidyr

The tidyr package is designed to aid in getting data frames into the 'variables as columns', 'observations as rows' form.

- For splitting or combining columns.
- For converting from wide to long format and vice-versa.

We'll illustrate this use through summarising the ED data using dplyr and converting that to `wide` tabular form using `spread` for presentation.

*Try the following*
```{r}
counts = ed %>%
            mutate(PRESENT = dmy_hm(PRESENT),
                   Hour = hour(PRESENT),
                   Weekday = wday(PRESENT, label=TRUE)) %>%
            group_by(Hour, Weekday) %>%
            summarise(count=n())
sp = spread(counts, key=Weekday, value=count)
print(sp, n=24)
gather(sp, Weekday, count, Sun:Sat)
```

*Your turn*

1. Construct a table of number of patients by ethnicity and age group.
2. Construct a table of median length of stay of patients by ethnicity and age group.

## Joins

Often we want to take one table and combine it with another to get additional information on observations.

This is particularly useful when there are grouping variables within the main data, where the grouping variable has
a number of other variables associated with it.

e.g. You might have other patient information available, or perhaps information on doctors.

In our case, we have `ComplaintCode` which is a cleaned up and coded version of the `Presenting.complaint` column.

*Take a look at it*
```{r}
select(ed, Presenting.complaint, ComplaintCode)
```

We then have a separate data table that tells us what these complaint codes are. This is known as 'normalised data', in that if
we want to change the labels of the complaint codes, we need only change the separated data table, and don't have to go through
and modify the ED database.

*Read the separate data table in*
```{r}
complaints = read.csv("data/ED_complaints.csv", stringsAsFactors = FALSE)
complaints
```

Our goal now is to link the main data frame to the complaints data frame, i.e. to lookup the complaint name using the complaint code.

You can do this using joins. Those of you familiar with databases will know about these already. The same types of joins you have on databases can also be done in dplyr.  The syntax of the joins are

```{r}
inner_join(x, y, by = NULL, copy = FALSE)
```

where you can replace `inner` by `left`, `right`, `full`, `semi` or `anti` to perform different join types.

- `inner_join` returns all rows from x that have a match in y, and all columns of x and y. If there are multiple matches, all matches are returned.
- `left_join` returns all rows from x, and all columns from x and y. Rows in x with no match in y will have NA values for the y columns. If there are multiple matches, all matches are returned.
- `right_join` returns all rows from y, and all columns from x and y. Rows in y with no match in x will have NA values for the x columns. Equivalent to `left_join(y, x) `
- `full_join` is a combination of left and right joins. All rows and columns from both x and y are returned, with any missing rows having NA values in the appropriate columns.
- `semi_join` returns rows from x that have a match in y, but only retains the columns of x. Note that this means that you never get rows duplicated like you do in an `inner_join` if there are repeats (as y columns aren't returned).
- `anti_join` returns rows from x with no matching rows in y, retaining only the columns of x.

By default, the join will use any common columns to use to match rows. You can override this with the `by` parameter.

*Try the following*
```{r}
inner_join(ed, complaints)
inner_join(ed, complaints, by=c("ComplaintCode" = "Code"))
```

*Your turn*

1. Create a table summarising the average emergency department stay by complaint and ethnicity.
2. Recall that in the EDA session we dealt only with the counts per hour. See if you can reconstruct that data set.
2. Play with the data and see what you can find.